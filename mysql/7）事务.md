写在前面：

数据库系统引入事务的目的在于：事务会把数据库从一种一致状态转换为另一种一致状态。

InnoDB存储引擎中的事务完全符合ACID的特性。ACID是以下四个词的缩写：

- 原子性 atomicity
- 一致性 consistency
- 隔离性 isolation
- 持久性 durability

上一章的锁，是探究InnoDB如何去实现事务的隔离性。本章主要关注事务的原子性。



## 7.1 认识事务

### 7.1.1 概述

事务是访问并更新数据库中各种数据项的一个程序执行单元。

部分数据库或者说存储引擎并没有严格去满足事务的ACID标准，但对于InnoDB而言，期默认的隔离级别read repeatable 是完全满足事务的ACID特性的。

简单介绍一下事务的ACID特性：

- A，原子性：指整个数据库事务是不可分割的工作单位
- C，一致性：将数据库从一种状态转变为另一种一致性的状态，在事务开始前与事务结束后，数据库的完整性约束没有被破坏。
- I，隔离性：还有其他称呼，诸如：并发控制、可串行化、锁等。事务的隔离性要求每个读写事务的对象对其他事务的操作对象能够相互分离，即钙食物提交前对其他事务不可见，通常这使用锁实现。
- D，持久性：事物一旦提交，其结果就是永久的。如果是物理层面的损坏，诸如磁盘问题，也可能导致数据丢失。因此持久性保证事务系统的高可靠性，而不是高可用性。



### 7.1.2 分类

从事务理论的角度，可以把事务分为以下几类：

- 扁平事务 flat transactions
- 带有保存点的扁平事务 flat transactions with savepoints
- 链事务 chained transactions
- 嵌套事务 nested transactions
- 分布式事务 distributed transactions

#### 扁平事务

​	扁平事务是最简单，也是使用最频繁的事务。在扁平事务中，所有操作处于同一层次，其内的所有操作是原子的。

![image-20210623083822388](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/扁平事务的三种情况.png)

​	扁平事务的限制在于无法针对事务的一部分进行提交或者回滚，也就是说，回滚或者提交都只能对于整个事务。因此就出现了带有保存点的扁平事务。

#### 带有保存点的扁平事务

​	带有保存点的扁平事务是在原有扁平事务的基础上，允许事务再执行过程中回滚到同一事务中较早的一个状态。这里的**保存点**，就是用来通过系统应该记住当前事务的状态，以便发生错误后，事务能够回到保存点当时的状态。

​	对于扁平事务，其隐式的设置了一个保存点，也就是事务开始时的状态，所以扁平事务只能回滚到事务开始时的状态。我们可以通过save work来显式新建保存点。当我们执行rollback work：2时，回回到保存点二 ，如果想要在此时执行真正的提交，还需要commit work 操作，需要回滚的话，需要执行rollback work。

![image-20210623084739756](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/在事务中使用保存点.png)

#### 链事务

​	链事务可认为是保存点模式的变种。当带有保存点的事务发送系统奔溃时，所有保存点会消失，事务需要从头开始。

​	链事务：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式的传给下一个要开始的事务。其实就是多个事务通过上下文隐式关联。

![image-20210623085609929](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/链事务.png)

​	所以在回滚时，链事务只能回滚当前事务，上一个事务其实是已经提交了的。不像带有保存点的扁平事务可以回滚到任意正确的保存点。由于链事务是多个事务，而带有保存点的事务是一个事务，所以前者的事务提交后，会释放当前事务的锁，后者则在新增保存点后继续持有锁，直到事务提交。

#### 嵌套事务

​	嵌套事务是一个层次结构的框架。

![image-20210623085546835](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/嵌套事务的层次结构.png)

​	Moss对于嵌套事务存在以下定义：

 1. 嵌套事务由若干事务组成的一棵树，子树即可以是嵌套事务，也可以是扁平事务。

 2. 处于也叶节点的是扁平事务。

 3. 处于根节点的是顶层事务，其他事务称为子事务。

 4. 子事务提交或者回滚后不会立即生效，需要等待其父事务提交，也就是必须等到顶层事务提交。

 5. 树中任意一个事务的回滚都会导致所有子事务一起回滚，所以子事务没有持久性（D）。

    我们可以通过保存点技术模拟嵌套事务，这有更大的灵活性，可以回滚到其他顶层事务中的某个状态，但也会导致事务中的锁一直是被保留的，不像嵌套事务，可以选择那些锁被子事务继承，哪些被父事务保留。

![image-20210623090452558](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/用保存点技术模拟嵌套事务.png)

当我们想要子事务并发执行时，通过上述方法模拟嵌套事务是不可取的，需要正在的嵌套事务。

而在InnoDB中，是不支持嵌套事务的，只能通过保存点技术来模拟。

#### 分布式事务

​	通常是在一个分布式的环境下运行的扁平事务，需要根据数据所在位置访问网络中的不同节点。每个节点执行的事务操作同样也是扁平的，任何一个节点的操作如果失败，都会导致整个分布式事务的回滚。



## 7.2 事务的实现



​	我们知道，事务存在四大特性，其中，事务的隔离性由锁来实现。原子性、一致性、持久性通过数据库的redo log 和undo log 来完成。redo log称为重做日志，用来保证事务的原子性和持久性。undo log 用来保证事务的一致性。

​	redo 与undo都可以视为恢复操作，其中redo恢复提交事务的页操作，而undo回滚行记录到某个特定版本。redo log为物理日志，记录的是对页的物理修改操作。undo log是逻辑日志，根据每行记录进行记录。

### 7.2.1 redo

#### 1.基本概念

​	重做日志用来实现事务的持久性。重做日志由两部分组成，分别是内存中的重做日志缓冲以及磁盘中的重做日志文件。

​	InnoDB在事务提交时，必须先将事务中所有日志写入到重做日志文件进行持久化，commit操作才算完成。redo log基本都是顺序写，在数据库运行时不需要对redo log 文件进行读取。为了确保每次日志都写入文件中，需要在将缓冲写入文件后，InnoDB都需要调用一次fsync操作，确保日志从文件系统缓存写入磁盘。

​	通过参数innodb_flush_log_at_trx_commit用来控制重做日志刷新到磁盘你的策略。默认值为1，表示事务提交后必须调用一次fsync，防止事务丢失。为0时表示事务提交后不写入重做日志，写入的操作仅在master thread 中完成（1秒一次fsync）。为2时表示在事务提交后写入文件系统的缓存，不进行fsync操作。设置为0和2时，会导致事务丧失ACID特性。

#### 2. log block

​	InnoDB中重做日志以512字节进行存储。意味着重做日志缓冲与重做日志文件都是以块的方式进行保存，称之为重做日志块（redo log block），每块大小为512字节。

​	若一个页中产生的重做日志数量大于512字节，会分割成多个日志块存储。同样，当少于512字节时，剩余的位置会被其他页中产生的重做日志填充。

​	重做日志除了日志本身外，还由日志块头（12字节）以及日志块尾（8字节）组成。所以实际存储的大小为492字节。其中log_block_hdr_no 与log_block_trl_no值相同。

![image-20210626151435624](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/重做日志块缓存的结构.png)

#### 3.log group

​	log group 为重做日志组，其中有多个重做日志文件。虽然源码中支持多个，但目前InnoDB中只有一个log group。其只是一个逻辑上的概念，并没有一个实际存储的物理文件来表示log group 的信息。

​	重做日志文件存储的就是log buffer中保存的log block。log buffer会按照一定规则将log block刷入磁盘：

- 事务提交
- 当log buffer中有一半的内存空间被使用
- log checkpoint时

对于log blokc 的写入追加在redo log file的最后部分。一个文件写满后，会接着写入下一个文件。那么这样的话，log block的写入是顺序的吗？其实并不是。

​	这是因为在redo log file中前2KB的部分不保存log block的信息，而是保存一些额外信息。所以在每次写入log block时，还回去更新前2KB部分的信息，这部分信息用于InnoDB的恢复。所以导致写入并非是顺序的。

![image-20210626154137360](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/redo log file 前2KB部分的内容.png)

​	之所以在log file header后交替写入checkpoint，是为了避免因为介质失败而无法找到可用给的checkpoint的情况。

#### 4. 重做日志格式

​	不同的数据库操作会有不同给的重做日志格式，由于InnoDB存储引擎的存储管理是基于页的，故其重做日志格式也是基于页的。

![image-20210626154434140](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/重做日志格式.png)

​	![image-20210626154512205](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/插入和删除的重做日志格式.png)

#### 5. LSN

​	LSN是log sequence number的缩写，其代表的是日志序列号。InnoDB中LSN占用8字节，并且单调递增。

​	LSN代表的含义有：

	- 重做日志写入的总量：内存中的LSN
	- checkpoint的位置：  redo log中的LSN
	- 页的版本：页头部中fil_page_lsn 记录了该页的LSN。在页中LSN表示该页最后刷新时LSN的大小。因为重做日志记录的是每个页的日志，因此页中的LSN用来判断页是否需要进行恢复操作。

#### 6.恢复

InnoDB在启动时不论上次是否正常关闭，都会尝试进行恢复操作。由于重做日志是物理日志，所以恢复速度比逻辑日志快，且其操作是幂等的。同时由于会顺序读取且并行应用重做日志，会进一步提高恢复速度。

checkpoint lsn是指已经刷新到磁盘的lsn。如下图的例子，数据库中checkpoint lsn的值为10000，所以恢复操作仅恢复lsn 10000~30000范围内的日志。

![image-20210626155437109](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/恢复的例子.png)

### 7.2.2 undo

#### 1.基本概念

##### redo 与 undo 差异	

重做日志可以记录事务的行为，在对页进行重做。但事务有时还需要进行回滚操作，这时就需要undo。当事务执行只是失败或者用户通过rollback进行回滚时，可以利用undo将数据回滚到修改之前的样子。

​	redo存放在重做文件中，而undo存放在数据库内部一个特殊的段中，这个段称为undo段。undo段位于共享表空间内。

​	redo 是物理日志，undo 是逻辑日志，只是将数据库逻辑的恢复到之前的样子。

​	undo log 也会产生 redo log，用来对undo log 进行持久性的保护。

##### undo 的作用

	1. 用做回滚
	2. MVCC：当用户读取一行记录时，如果该记录被其他事务占用，可以同undo 读取之前的行版本信息，用来实现非锁定读。

#### 2.undo存储管理

​	InnoDB对undo 的管理采用段的方式。在InnoDB中有rollback segent，每个回滚段中记录了1024个undo log segment	在每个undo log segment段中进行undo页的申请。我们可以在共享表空间内偏移量为5的页记录了所有rollback segment header所在的页，这个页的类型是fil_page_type_sys。InnoDB默认支持128个rollback segment。默认支持在线事务128*1024。

​	可以通过三个参数对回滚段进行设置。

​	innodb_undo_directory：设置回滚段的所在路径。

​	innodb_undo_logs：设置回滚段的个数，默认为128个。

​	innodb_undo_tablespaces：设置构成回滚段的文件数量，是回滚段平均的分布在多个文件中。文件前缀为undo。

​	

​	上面我们提到在写入undo log时会写入对应的redo log，所以在事务提交时会做两件事情：

  		1. 将undo log 放入列表中，以供之后的purge操作
  		2. 判断undo log 所在页是否可以重用，如果可以，分配给下个事务使用



​	在事务提交时并不能立马删除undo log 以及undo log 所在页因为还需要通过undo 实现MVCC。所以需要将undo log 放入链表中，通过purge线程来判断是否可以最终删除undo log 以及undo log 所在页。

​	在事务提交后，会判断undo页的使用空间是否小于3/4，若是则认为该undo页可以重用，之后新的undo log记录在当前undo log的后面。这导致undo页存放着不同事务的undolog，purge操作也会需要对磁盘进行离散读取操作。



​	通过show engine innodb status 查看undo log 的数量，对应字段为history list length。purge操作会减少该值。

#### 3.undo log 格式

​	InnoDB中undo log 分为 insert undo log 以及 update undo log。

​	insert undo log 是指insert操作产生的undo log，在事务提交后会直接删除，不需要进行purge。因为事务隔离性的要求，对于insert 操作的记录，只对当前事务本身可见，其他事务不可见。

​	update undo log 是指delete和update 操作产生的undo log。由于可能提供MVCC，所以不能在事务提交后直接删除。

![image-20210626165823605](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/insert undo log 格式以及 update undo log格式.png)

#### 4.查看undo信息

​	我们可以通过innodb_trx_rollback_segment、innodb_trx_undo查看undo的信息。

​	innodb_trx_rollback_segment用来查看回滚段相关信息。

​	innodb_trx_undo查看事务对应的undo log。

#### 7.2.3 purge

​	purge用于最终完成delete和update操作。

​	InnoDB有一个history列表，用于存放undo log，顺序就是事务提交的顺序。

​	在purge过程中，InnoDB回显从list中找到第一个需要被清理的记录，这里为trx1，清理后会在trx1对应的undo log 页中继续寻找可以被清理的事务（为了尽可能避免随机读取操作），这里是trx3、trx5，由于trx被引用，只会清除trx3，然后回到list中依次清理。

![image-20210626171943016](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/undo log 与history list的关系.png)



​	我们可以通过innodb_purge_batch_size来控制每次purge操作需要清理的undo page 数量。默认为300。值越大，越消耗CPU以及IO资源，但会减少磁盘存储空间以及分配的开销。值越小，消耗CPU以及IO资源越小，但可供重用的undo page越少，磁盘存储空间以及分配的开销越大。

​	我们可以通过innodb_max_purge_lag控制history list的长度，当长度大于该参数时，会延缓DML操作，使得purge有时间回收undo page。同时有innodb_max_purge_lag_delay控制最大的延迟时间，避免purge被延缓到无限制的等待。



### 7.2.4 group commit

​	在每次事务提交时基本上都会进行一次fsync操作，以此保证重做日志都已经写入磁盘。当前数据库都提供了group commit功能，在一次fsync可以刷新多个事务日志到文件中。

​	在innodb中，事务提交会进行两个阶段的操作。

	1. 修改内存中事务的信息，将日志写入重做日志缓冲。
	2. 调用fsync将日志从重做日志缓冲写入磁盘。

​	由于步骤2较慢，所以数据库支持将多个事务的重做日志通过一次fsync刷新到磁盘，减少磁盘的压力。但当开启binlog时，为了保证存储引擎中的事务与二进制日志的一致性，会导致group commit 失效。

具体的原因：

> ​	开启binlog时，会使用两阶段提交：
>
> ​	1）事务提交时InnoDB进行prepare操作
>
> ​	2）mysql数据库上传写入binlog
>
> ​	3）Innodb将日志写入重做日志文件
>
> ​		a) 修改内存中事务的信息，将日志写入重做日志缓冲。
>
> ​		b) 调用fsync将日志从重做日志缓冲写入磁盘。
>
> ![image-20210626173840844](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/开启binlog后InnoDB的提交过程.png)

​	为了保证binlog的写入顺序与InnoDB的事务提交顺序一致（为了备份与恢复的需要），MySQL的内部使用了prepare_commit_mutex这个锁。启用这个锁之后，会导致group commit 失效。

​	为了解决上述出现的问题，后续出现了binary log group commit（BLGC）技术，对redo log 与binlog进行组提交。

![image-20210626174714733](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/BLGC的实现方式.png)

​	flush：将事务的binlog写入内存

​	sync：将内存中的binlog刷新到磁盘，是一个批量操作，会刷新多个binlog

​	commit：根据上一步中批量刷新的顺序，调用存储引擎层的事务提交

这里建议参看这篇文章：

5.7版本 ：https://cloud.tencent.com/developer/article/1429685 

5.6 5.7 http://mysql.taobao.org/monthly/2020/05/07/



5.6 版本：InnoDB prepare操作做的事情：设置回滚段为prepare，写入文件系统缓存并刷盘redo log。

5.6 版本：InnoDB prepare操作做的事情：设置回滚段为prepare，写入文件系统缓存redo log。在BLGC的flush阶段，一次性对所有redo log 进行刷盘，再将binglog 内存缓存写入binlog 文件缓存。



## 7.6 事务的隔离级别

SQL标准中定义了四个隔离标准：

- read uncommitted
- read committed
- repeatable read
- seriable

读未提交称为浏览器访问。读已提交称为游标稳定。可重复读是2.999度的隔离，没有幻读的保护。串行化被称为隔离或者3度的隔离。

​	InnoDB默认支持的隔离级别是可重复读，与标准SQL不同的是，由于使用了next-key lock锁算法，因此避免了幻读的产生。

​	事务隔离级别越低，事务请求的锁越少或者保持锁的时间就越短。在在《Transaction Processing》书中支出，可重复读与串行化的开销几乎一样，甚至串行化可能更优。

​	串行化的事务隔离级别下，InnoDB会对每个查询语句添加共享锁，使得一致性的锁定读不再给予支持。

​	可重复读的事务隔离级别下，InnoDB已经可以达到完整的3度的隔离，所以本地事务使用该事务级别就够了，除非是分布式事务才会使用串行化的隔离级别。

​	读已提交的事务隔离级别下，除了唯一键的约束以及外键约束的检查会使用到gap lock，InnoDB不会使用gap lock 的锁算法。



## 7.7 分布式事务

### 7.7.1 Mysql数据库分布式事务

​	InnoDB提供了对XA事务的支持，通过XA事务来支持分布式事务的实现。分布式事务是指允许多个独立的事务资源参与到一个全局的事务中。在使用分布式事务时，InnoDB事务隔离级别要设置为可串行化。

​	XA事务有一个或多个资源管理器、一个事务管理器、以及一个应用程序组成。

	- 资源管理器：resoruce managers 提供访问事务资源的方法。通常一个数据库就是一个资源管理器。
	- 事务管理器：transaction manager 协调参与全局事务中的各个失误。需要个所有资源管理器进行通信。
	- 应用程序：applaction program 定义事务的边界，指定全局事务中的操作。

![image-20210627152842670](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/分布式事务模型.png)

### 7.7.2 内部XA事务

Mysql内部存在另一种分布式事务，在存储引擎与插件之间或者在存储引擎与存储引擎之间，称为内部XA事务。

​	最常见的内部XA事务在于binlog与InnoDB之间。在开启binlog后一般要先写binlog，再写重做日志，需要保证两者必须同时写入，不能丢失。如果binlog写入后，InnoDB发生了宕机，那么slave可能会接收master闯过去的二进制文件并执行，最终导致主从不一致。如下图中，3）没有执行，会发生不一致。

![image-20210627153539605](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/宕机导致主从不一致.png)

​		为了解决这个问题，MySQL在binlog与InnoDB之间采用了XA事务。事务提交时回显进行prepare操作，将事务的xid写入，然后写入binlog，如果InnoDB提交前发生了宕机，重启后会检查准备的xid事务是否以提交，若没有，会在存储引擎层再进行一次提交操作。

![image-20210627153823762](/Users/chenjiehao/Library/Mobile Documents/com~apple~CloudDocs/study/image/Mysql通过内部XA避免主从数据不一致.png)

